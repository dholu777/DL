{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvEwvPu32RSE"
   },
   "source": [
    "# Feedforward Neural Network Implementation with Keras and TensorFlow: CIFAR-10 Dataset\n",
    "This Jupyter notebook demonstrates the implementation of a feedforward neural network using Keras and TensorFlow. The goal of this assignment is to walk through the process of building, training, and evaluating a neural network for image classification. We will use the MNIST or CIFAR-10 dataset as per your choice.<br>\n",
    "Dataset: https://www.cs.toronto.edu/%7Ekriz/cifar.html <br>\n",
    "Info: The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "## Assignment Steps:\n",
    "\n",
    "**a. Import the necessary packages**: We will start by importing the required Python libraries, including Keras, TensorFlow, and other essential packages.\n",
    "\n",
    "**b. Load the training and testing data**: In this step, we will load the dataset (either MNIST or CIFAR-10) for training and testing the neural network.\n",
    "\n",
    "**c. Define the network architecture using Keras**: Here, we will define the architecture of our feedforward neural network, specifying the number of layers, neurons, and activation functions.\n",
    "\n",
    "**d. Train the model using SGD (Stochastic Gradient Descent)**: We will use the Stochastic Gradient Descent optimizer to train the neural network on the training data.\n",
    "\n",
    "**e. Evaluate the network**: After training, we will evaluate the performance of the model on the testing data to assess its accuracy and other relevant metrics.\n",
    "\n",
    "**f. Plot the training loss and accuracy**: We will create plots to visualize the training loss and accuracy over epochs, providing insights into the model's learning progress.\n",
    "\n",
    "Feel free to follow along with the code and explanations provided in this notebook to gain a better understanding of building and training neural networks for image classification.\n",
    "\n",
    "# Build the Image classification model by dividing the model into following 4 stages:\n",
    "a. Loading and preprocessing the image data<br>\n",
    "b. Defining the model’s architecture<br>\n",
    "c. Training the model<br>\n",
    "d. Estimating the model’s performance<br>\n",
    "\n",
    "Note: Both assignment can use this code accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWZq69pHyS9G"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow matplotlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cifar10 = tf.keras.datasets.cifar10 # Importing cifar10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() # Splitting it into training and testing data\n",
    "\n",
    "for i in (x_train, y_train, x_test, y_test):\n",
    "  print(i.shape)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(x_train[25])\n",
    "print(y_train[25])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#scaling the values\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "# 0/255 = 255\n",
    "#255/255 = 1 maximum value\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Create a sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))  # 10 classes for classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary to check the architecture\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=30,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.lineplot(model.history.history)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the Model Accuracy & Model Loss vs Epochs\n",
    "plt.figure(figsize=[10,8])\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy', size=25, pad=20)\n",
    "plt.ylabel('Accuracy', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss', size=25, pad=20)\n",
    "plt.ylabel('Loss', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(x_test[0].reshape(32, 32, -1))\n",
    "plt.title(\"Predicted value: \" + str(class_names[np.argmax(predictions[0], axis=0)]), size=20)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(x_test[100].reshape(32, 32, -1))\n",
    "plt.title(\"Predicted value: \" + str(class_names[np.argmax(predictions[100], axis=0)]), size=20)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMj3Pq9EmwscXz1+79sNmsM",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
