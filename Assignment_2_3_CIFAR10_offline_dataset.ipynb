{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network Implementation with Keras and TensorFlow: CIFAR-10 Dataset\n",
    "This Jupyter notebook demonstrates the implementation of a feedforward neural network using Keras and TensorFlow. The goal of this assignment is to walk through the process of building, training, and evaluating a neural network for image classification. We will use the MNIST or CIFAR-10 dataset as per your choice.<br>\n",
    "Dataset: https://www.cs.toronto.edu/%7Ekriz/cifar.html <br>\n",
    "Info: The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "## Assignment Steps:\n",
    "\n",
    "**a. Import the necessary packages**: We will start by importing the required Python libraries, including Keras, TensorFlow, and other essential packages.\n",
    "\n",
    "**b. Load the training and testing data**: In this step, we will load the dataset (either MNIST or CIFAR-10) for training and testing the neural network.\n",
    "\n",
    "**c. Define the network architecture using Keras**: Here, we will define the architecture of our feedforward neural network, specifying the number of layers, neurons, and activation functions.\n",
    "\n",
    "**d. Train the model using SGD (Stochastic Gradient Descent)**: We will use the Stochastic Gradient Descent optimizer to train the neural network on the training data.\n",
    "\n",
    "**e. Evaluate the network**: After training, we will evaluate the performance of the model on the testing data to assess its accuracy and other relevant metrics.\n",
    "\n",
    "**f. Plot the training loss and accuracy**: We will create plots to visualize the training loss and accuracy over epochs, providing insights into the model's learning progress.\n",
    "\n",
    "Feel free to follow along with the code and explanations provided in this notebook to gain a better understanding of building and training neural networks for image classification.\n",
    "\n",
    "# Build the Image classification model by dividing the model into following 4 stages:\n",
    "a. Loading and preprocessing the image data<br>\n",
    "b. Defining the model’s architecture<br>\n",
    "c. Training the model<br>\n",
    "d. Estimating the model’s performance<br>\n",
    "\n",
    "Note: Both assignment can use this code accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow matplotlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the paths to the training and testing data directories\n",
    "# D:\\Eng\\B.E\\DL\\deepLearning\\dataset\\cifar-10-img\\cifar-10-img\\train\n",
    "train_data_dir = 'dataset/cifar-10-img/cifar-10-img/train'\n",
    "test_data_dir = 'dataset/cifar-10-img/cifar-10-img/test'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Set up an ImageDataGenerator to rescale pixel values to [0, 1]\n",
    "image_data_generator = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Define batch sizes\n",
    "train_batch_size = 20000\n",
    "test_batch_size = 2000\n",
    "\n",
    "# Create data generators for training and testing\n",
    "train_generator = image_data_generator.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(32, 32),  # Resize images to 28x28 pixels\n",
    "    batch_size=train_batch_size,  # Number of images per training batch\n",
    "    class_mode='categorical',  # One-hot encoded labels\n",
    "    shuffle=True,  # Shuffle the order of images during training\n",
    ")\n",
    "\n",
    "test_generator = image_data_generator.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(32, 32),  # Resize images to 28x28 pixels\n",
    "    batch_size=test_batch_size,  # Number of images per testing batch\n",
    "    class_mode='categorical',  # One-hot encoded labels\n",
    "    shuffle=True,  # Shuffle the order of images during testing\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = train_generator[0]\n",
    "x_test, y_test = test_generator[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Shape of X_train {x_train.shape}\")\n",
    "print(f\"Shape of y_train {y_train.shape}\")\n",
    "print(f\"Shape of x_test  {x_test.shape}\")\n",
    "print(f\"Shape of y_test  {y_test.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "x_train.shape[1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a list of layers\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "# Compile the model\n",
    "sgd_optimizer = SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(x_train, y_train,\n",
    "              batch_size=20,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.lineplot(model.history.history)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Loss: \", test_loss)\n",
    "print(\"Accuracy: \", test_acc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predicted_value=model.predict(x_test)\n",
    "plt.imshow(x_test[50])\n",
    "plt.show()\n",
    "print(class_names[np.argmax(predicted_value[50], axis=0)])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_env",
   "language": "python",
   "name": "lab_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
